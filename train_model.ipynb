{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#### This is for the growth of the memory usage as is needed by the process ####### \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the fourth GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82657, 12) (20665, 11)\n"
     ]
    }
   ],
   "source": [
    "####  loading data ######\n",
    "train=pd.read_csv('D:/My stuff/ML TASK INTERNSHALA/Knight ML Assignment/Data/train.csv')\n",
    "test=pd.read_csv('D:/My stuff/ML TASK INTERNSHALA/Knight ML Assignment/Data/test.csv')\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### dropping user name as it is not relevant for the features ###########\n",
    "train=train.drop(['user_name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Search years and make another column for years ######\n",
    "import re\n",
    "year = []  \n",
    "for value in train['review_title']:\n",
    "    res = re.search(r'19\\d{2}|20\\d{2}', value)\n",
    "    if res:\n",
    "        year.append(res.group())\n",
    "    else: year.append(None)\n",
    "\n",
    "train['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2528 rows with empty year values.\n",
      "\n",
      "count                                                 80129\n",
      "unique                                                    1\n",
      "top       0        2007\\n1        2014\\n2        2007\\n3...\n",
      "freq                                                  80129\n",
      "Name: year, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "##### Removing rows which dont have years #######\n",
    "df_final=train\n",
    "df_final=df_final.dropna(subset=['year'])\n",
    "print('Removed ' + str(train.shape[0]-df_final.shape[0]) + ' rows with empty year values.' + \"\\n\")\n",
    "\n",
    "df_final['year']=str(df_final['year'])\n",
    "\n",
    "\n",
    "print(df_final['year'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     80129\n",
       "unique        1\n",
       "top       False\n",
       "freq      80129\n",
       "Name: year, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.year.isnull().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "######## Adding all the field together so as to gather all the necessary information ######\n",
    "df_final.fillna(' ')\n",
    "df_final['new']=df_final['country'].astype(str)+' '+df_final['review_title'].astype(str)+' '+df_final['review_description'].astype(str)+' '+df_final['designation'].astype(str)+' '+df_final['province'].astype(str)+' '+df_final['region_1'].astype(str)+' '+df_final['winery'].astype(str)+' '+df_final['year'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "82652    False\n",
       "82653    False\n",
       "82654    False\n",
       "82655    False\n",
       "82656    False\n",
       "Name: new, Length: 80129, dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.new.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia Andrew Peace 2007 Peace Family Vineyard Chardonnay (South Eastern Australia) Classic Chardonnay aromas of apple, pear and hay lead into a palate marked by decent intensity but also a bit of sweetness. Orange and candy notes run through the rather short finish. Peace Family Vineyard Australia Other South Eastern Australia Andrew Peace 0        2007\n",
      "1        2014\n",
      "2        2007\n",
      "3        2010\n",
      "4        2012\n",
      "         ... \n",
      "82652    2007\n",
      "82653    2008\n",
      "82654    2014\n",
      "82655    2011\n",
      "82656    2010\n",
      "Name: year, Length: 80129, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#### stopword list ######\n",
    "sw = stopwords.words('english')\n",
    "X=df_final['new']\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### making a list of word that will help in the classification ######\n",
    "list_of_words = []\n",
    "for phase_word in X:\n",
    "    list_of_words.append(' '.join([re.sub('[^a-zA-Z0-9]', '', word) for word in phase_word.split() if not word in sw]))\n",
    "X = list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### using the TFIDF as the countvectorization ######\n",
    "tfidf = TfidfVectorizer(min_df=5)\n",
    "X = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting the variety and making the y variable that we will predict ####\n",
    "y=df_final['variety']\n",
    "df_final=df_final.drop(['variety'],axis=1)\n",
    "### label encoding the data #####\n",
    "labelEncoder = LabelEncoder()\n",
    "y = labelEncoder.fit_transform(y)\n",
    "### Splitting data into train and test ######\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "64103/64103 [==============================] - 26s 408us/step - loss: 0.7921 - accuracy: 0.8092\n",
      "Epoch 2/2\n",
      "64103/64103 [==============================] - 24s 376us/step - loss: 0.1027 - accuracy: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x264f26d6b88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Model creation ######\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=len(tfidf.get_feature_names())))\n",
    "model.add(Dense(units=y.max()+1, activation='sigmoid'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16026/16026 [==============================] - 4s 231us/step\n",
      "The accuracy of the model is 0.9561337828636169\n"
     ]
    }
   ],
   "source": [
    "### predictions and accuracy ####\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print ('The accuracy of the model is %s' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## formatting the test data correctly to input into the model ######\n",
    "def correctFormat(df):\n",
    "    df=df.drop(['user_name'],axis=1)\n",
    "    year = []  \n",
    "    for value in df['review_title']:\n",
    "        res = re.search(r'19\\d{2}|20\\d{2}', value)\n",
    "        if res:\n",
    "            year.append(res.group())\n",
    "        else: year.append(None)\n",
    "    df['year'] = year\n",
    "    df_final=df\n",
    "    df_final=df_final.dropna(subset=['year'])\n",
    "    df_final['year']=str(df_final['year'])\n",
    "    df_final.fillna(' ')\n",
    "    df_final['new']=df_final['country'].astype(str)+' '+df_final['review_title'].astype(str)+' '+df_final['review_description'].astype(str)+' '+df_final['designation'].astype(str)+' '+df_final['province'].astype(str)+' '+df_final['region_1'].astype(str)+' '+df_final['winery'].astype(str)+' '+df_final['year'].astype(str)\n",
    "    sw = stopwords.words('english')\n",
    "    X=df_final['new']\n",
    "    list_of_words = []\n",
    "    for phase_word in X:\n",
    "        list_of_words.append(' '.join([re.sub('[^a-zA-Z0-9]', '', word) for word in phase_word.split() if not word in sw]))\n",
    "    X = list_of_words\n",
    "    #tfidf = TfidfVectorizer(min_df=5)\n",
    "    X = tfidf.transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "D:\\Anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_format=correctFormat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20059, 18396) (64103, 18396)\n"
     ]
    }
   ],
   "source": [
    "print(test_format.shape,X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### predicting on test cases #####\n",
    "predictions_test=model.predict_classes(test_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_t=predictions_test\n",
    "pd_t_label=labelEncoder.inverse_transform(pd_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pinot Noir'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_t_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the predictions into txt file ##### \n",
    "f=open('predictions_for_testcsv.txt','w')\n",
    "for i in range(len(pd_t_label)):\n",
    "    f.write(str(pd_t_label[i])+'\\n')\n",
    "    \n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the model #####\n",
    "model.save('model_withoutKfold.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
