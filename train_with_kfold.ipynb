{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "#### FOR THE COMMENTS SEE THE train_model.ipynb FILE #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#### This is for the growth of the memory usage as is needed by the process ####### \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the fourth GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82657, 12) (20665, 11)\n"
     ]
    }
   ],
   "source": [
    "####  loading data ######\n",
    "train=pd.read_csv('D:/My stuff/ML TASK INTERNSHALA/Knight ML Assignment/Data/train.csv')\n",
    "test=pd.read_csv('D:/My stuff/ML TASK INTERNSHALA/Knight ML Assignment/Data/test.csv')\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82657, 12)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### dropping user name as it is not relevant for the features ###########\n",
    "train=train.drop(['user_name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82657, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Search years and make another column for years ######\n",
    "import re\n",
    "year = []  \n",
    "for value in train['review_title']:\n",
    "    res = re.search(r'19\\d{2}|20\\d{2}', value)\n",
    "    if res:\n",
    "        year.append(res.group())\n",
    "    else: year.append(None)\n",
    "\n",
    "train['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2528 rows with empty year values.\n",
      "\n",
      "count                                                 80129\n",
      "unique                                                    1\n",
      "top       0        2007\\n1        2014\\n2        2007\\n3...\n",
      "freq                                                  80129\n",
      "Name: year, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "##### Removing rows which dont have years #######\n",
    "df_final=train\n",
    "df_final=df_final.dropna(subset=['year'])\n",
    "print('Removed ' + str(train.shape[0]-df_final.shape[0]) + ' rows with empty year values.' + \"\\n\")\n",
    "\n",
    "df_final['year']=str(df_final['year'])\n",
    "\n",
    "\n",
    "print(df_final['year'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     80129\n",
       "unique        1\n",
       "top       False\n",
       "freq      80129\n",
       "Name: year, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.year.isnull().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "######## Adding all the field together so as to gather all the necessary information ######\n",
    "df_final.fillna(' ')\n",
    "df_final['new']=df_final['country'].astype(str)+' '+df_final['review_title'].astype(str)+' '+df_final['review_description'].astype(str)+' '+df_final['designation'].astype(str)+' '+df_final['province'].astype(str)+' '+df_final['region_1'].astype(str)+' '+df_final['winery'].astype(str)+' '+df_final['year'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "82652    False\n",
       "82653    False\n",
       "82654    False\n",
       "82655    False\n",
       "82656    False\n",
       "Name: new, Length: 80129, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.new.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia Andrew Peace 2007 Peace Family Vineyard Chardonnay (South Eastern Australia) Classic Chardonnay aromas of apple, pear and hay lead into a palate marked by decent intensity but also a bit of sweetness. Orange and candy notes run through the rather short finish. Peace Family Vineyard Australia Other South Eastern Australia Andrew Peace 0        2007\n",
      "1        2014\n",
      "2        2007\n",
      "3        2010\n",
      "4        2012\n",
      "         ... \n",
      "82652    2007\n",
      "82653    2008\n",
      "82654    2014\n",
      "82655    2011\n",
      "82656    2010\n",
      "Name: year, Length: 80129, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#### stopword list ######\n",
    "sw = stopwords.words('english')\n",
    "X=df_final['new']\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = []\n",
    "for phase_word in X:\n",
    "    list_of_words.append(' '.join([re.sub('[^a-zA-Z0-9]', '', word) for word in phase_word.split() if not word in sw]))\n",
    "X = list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=5)\n",
    "X = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_final['variety']\n",
    "df_final=df_final.drop(['variety'],axis=1)\n",
    "labelEncoder = LabelEncoder()\n",
    "y = labelEncoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=len(tfidf.get_feature_names())))\n",
    "model.add(Dense(units=y.max()+1, activation='sigmoid'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "64103/64103 [==============================] - 23s 356us/step - loss: 0.7818 - accuracy: 0.8090\n",
      "Epoch 2/2\n",
      "64103/64103 [==============================] - 22s 350us/step - loss: 0.1034 - accuracy: 0.9739\n",
      "16026/16026 [==============================] - 4s 237us/step\n",
      "Epoch 1/2\n",
      "64103/64103 [==============================] - 23s 354us/step - loss: 0.0623 - accuracy: 0.9831\n",
      "Epoch 2/2\n",
      "64103/64103 [==============================] - 24s 370us/step - loss: 0.0285 - accuracy: 0.9932\n",
      "16026/16026 [==============================] - 4s 252us/step\n",
      "Epoch 1/2\n",
      "64103/64103 [==============================] - 24s 371us/step - loss: 0.0264 - accuracy: 0.9927\n",
      "Epoch 2/2\n",
      "64103/64103 [==============================] - 23s 356us/step - loss: 0.0117 - accuracy: 0.9972\n",
      "16026/16026 [==============================] - 4s 226us/step\n",
      "Epoch 1/2\n",
      "64103/64103 [==============================] - 23s 363us/step - loss: 0.0135 - accuracy: 0.9963\n",
      "Epoch 2/2\n",
      "64103/64103 [==============================] - 24s 373us/step - loss: 0.0056 - accuracy: 0.9986\n",
      "16026/16026 [==============================] - 4s 248us/step\n",
      "Epoch 1/2\n",
      "64103/64103 [==============================] - 24s 378us/step - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 2/2\n",
      "64103/64103 [==============================] - 22s 343us/step - loss: 0.0029 - accuracy: 0.9992\n",
      "16026/16026 [==============================] - 4s 220us/step\n"
     ]
    }
   ],
   "source": [
    "#### APPLYING KFOLD CROSSVALIDATION ######\n",
    "from sklearn.model_selection import KFold\n",
    "kf=KFold(n_splits=5,shuffle=True)\n",
    "scores=[]\n",
    "for i in range(5):\n",
    "    result=next(kf.split(X),None)\n",
    "    X_train=X[result[0]]\n",
    "    X_test=X[result[1]]\n",
    "    y_train=y[result[0]]\n",
    "    y_test=y[result[1]]\n",
    "    his=model.fit(X_train,y_train,epochs=2,verbose=1)\n",
    "    pred=model.predict(X_test)\n",
    "    scores.append(model.evaluate(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores from each: [[0.13682894687460379, 0.9596281051635742], [0.06445641860238134, 0.9790964722633362], [0.03557988968428513, 0.9885186553001404], [0.018791850644648337, 0.9945089221000671], [0.009866702124250604, 0.997316837310791]]\n"
     ]
    }
   ],
   "source": [
    "print('Scores from each:',scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: [0.9838137984275818]\n"
     ]
    }
   ],
   "source": [
    "mean_sco=[np.mean([scores[i][1] for i in range(len(scores))])]\n",
    "print('Average score:', mean_sco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_kfold.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctFormat(df):\n",
    "    df=df.drop(['user_name'],axis=1)\n",
    "    year = []  \n",
    "    for value in df['review_title']:\n",
    "        res = re.search(r'19\\d{2}|20\\d{2}', value)\n",
    "        if res:\n",
    "            year.append(res.group())\n",
    "        else: year.append(None)\n",
    "    df['year'] = year\n",
    "    df_final=df\n",
    "    df_final=df_final.dropna(subset=['year'])\n",
    "    df_final['year']=str(df_final['year'])\n",
    "    df_final.fillna(' ')\n",
    "    df_final['new']=df_final['country'].astype(str)+' '+df_final['review_title'].astype(str)+' '+df_final['review_description'].astype(str)+' '+df_final['designation'].astype(str)+' '+df_final['province'].astype(str)+' '+df_final['region_1'].astype(str)+' '+df_final['winery'].astype(str)+' '+df_final['year'].astype(str)\n",
    "    sw = stopwords.words('english')\n",
    "    X=df_final['new']\n",
    "    list_of_words = []\n",
    "    for phase_word in X:\n",
    "        list_of_words.append(' '.join([re.sub('[^a-zA-Z0-9]', '', word) for word in phase_word.split() if not word in sw]))\n",
    "    X = list_of_words\n",
    "    #tfidf = TfidfVectorizer(min_df=5)\n",
    "    X = tfidf.transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "D:\\Anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_format=correctFormat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20059, 18396) (64103, 18396)\n"
     ]
    }
   ],
   "source": [
    "print(test_format.shape,X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test=model.predict_classes(test_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_t=predictions_test\n",
    "pd_t_label=labelEncoder.inverse_transform(pd_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the predictions into txt file ##### \n",
    "f=open('predictionsKFOLD_for_testcsv.txt','w')\n",
    "for i in range(len(pd_t_label)):\n",
    "    f.write(str(pd_t_label[i])+'\\n')\n",
    "    \n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
